\part{Conclusion and perspectives}
\label{part:conclusion}

In this thesis we presented our work on device-independent quantum information protocols, improving them with the end goal of easing their experimental implementations, and answering some fundamental questions along the way.
As quantum information applications are expected to have an important impact on current technologies, notably revolutionizing computation and communication tasks, the device-independent framework appears as a necessity.
Indeed, for quantum information protocols to replace their current classical counterparts, stable and robust implementations are as crucial as improved performances. 
Moreover, in a global world where communication is key and where manufacturing is scattered across numerous actors, there is the need for cryptographic systems which not only come with the highest security proofs but also with the capability to detect the presence of interferences from the devices they rely on.
Device-independent protocols address these concerns by allowing certifications of resources and security guarantees without relying on assumption on their inner working. 

%In the first part of this thesis, we analyzed self-testing, the simplest and most fundamental device-independent protocol, which enables the certification of some quantum resources.
%In a second part, we explored device-independent quantum key distribution, a device-independent approach to quantum cryptography, allowing two parties to share a secret symmetric key with a provable security guarantee, based on the fundamental laws of physics. 
%
%In this last part, we briefly recall the results we developed in this thesis before discussing some open questions raised by our contributions as well as by other recent works in the field.
%Finally, we put device-independent protocols, and in particular self-testing and DIQKD, into a boarder perspective.
%We show how these protocols could help build a quantum internet, therefore enhancing the computation and communication capabilities of humanity.

\paragraph{Self-testing} 

In the first part of this thesis, we study the most fundamental device-independent protocol, self-testing.
Self-testing enables the device-independent certification of certain quantum resources from the presence of specific non-local correlations.
In particular, from the maximal CHSH score, it is possible to self-test two-qubit maximally entangled states and maximally incompatible measurements.
For real world applications, robust singlet self-testing provides the certification of a singlet-fraction from lower violation of the CHSH inequality, naturally occurring in a noisy and lossy regime. 
One of our contributions to this topic concerns the quantification of the fundamental resources that are required for robust self-testing of the singlet.
Notably, we showed that the CHSH score $S\approx 2.05$ is a threshold below which robust self-testing fails~\cite{Valcarce2020}.
From the relatively high value of this threshold, we emphasized the need for new robust self-testing protocols which provide certification beyond the CHSH score.
To tackle this matter, we formulated an original protocol in \cite{Valcarce2022}, leveraging the available information of correlators pair to provide better robustness bounds without changing experimental requirements.
Interestingly, in the case of imbalanced noises, our protocol allows for self-tests below the CHSH threshold of $S\approx 2.05$ and even as close as the local bound, $S=2$, providing an asymmetric enough noise. 
Our new protocol, henceforth, eases the experimental realization of device-independent protocols based on the certification of singlet states.


\medbreak

Our results on self-testing, show the need for more robust self-testing protocols, point at directions where improvements can be obtained, and raise some more fundamental questions.
First, the CHSH-score threshold we derived is still far from the bound $S\approx 2.11$ given by the best known CHSH-based self-testing protocol~\cite{Kaniewski2016}.
Therefore an improvement is to be expected on the threshold or on the local isometries proposed in \cite{Kaniewski2016} or both.
Then, analogously to what has been done for DIQKD~\cite{Brown2021}, one can hope for a robust self-testing protocol harnessing all of the available statistics.
Insights obtained from our generalized-CHSH based self-test show that such a protocol should help providing self-tests that are robust to any type of noises.
This would be a crucial step not only to ease the implementation of self-testing, but also to make self-testing a handy and flexible certification tool, that could be used as a complementary tool with tomography.
Finally, better robustness bound could arise when considering a scenario with more than 2 inputs and outputs.
However, this would requires derivations that does not rely on Jordan's lemma.
If the SWAP method provide a numerical solution to self-testing from all the correlations and without relying on Jordan's lemma, its general scope yields suboptimal extractability bound in the case of the singlet~\cite{Yang2014,Bancal2015}.
An improved SWAP method may thus be derived.
Elements from the approach \cite{Brown2021} may be useful to tackle this problem as well.

\medbreak

More broadly, robust self-testing methods should be extended to enable the certification of not just states, but entire quantum systems.
First, the robust self-testing of quantum channels, introduced in \cite{Sekatski2018}, could be extended to certify quantum measurements beyond commutation~\cite{Kaniewski2017}.
A framework for the robust self-testing of joint quantum measurements beyond the Bell-state measurement~\cite{Bancal2018,Renou2018} could then be developed.
Finally, this may lead to \textit{complete self-tests}, certifying at once both states and measurements.
For each of these methods, it is desired to have proofs valid in non-IID scenarios to enable practical applications.
Intuitively, the approach based on estimators on the statistics demonstrated in \cite{Bancal2021} could be extended to these more complete self-tests. 


%Similarly to what is done with the self-test of quantum state, propose a way to robust self-test measurement.
%This could lead to the robust self-test of entire quantum channel or even of quantum circuits.
%This method could be use as a complementary approach to quantum tomography, allowing to debug system.

\paragraph{DIQKD}

In the second part of this thesis, we focus on \acrfull{DIQKD}, the protocol allowing two parties to share a secret and identical cryptographic key in a provable way.
Security proofs are commonly found in the form of a key rate guaranteeing a fraction of secure key bit per protocol run.
After the derivation of a first practical key rate from the CHSH score, numerous improvements pushed that key rate to higher values and increased its robustness to losses.
On the experimental side, photonic setups seem the most promising platform for long-term DIQKD applications.
However, the SPDC setup -- the photonic implementation successfully used in Bell tests -- only achieves low CHSH score in realistic efficiency regimes, thus yielding key rates that are only slightly positive.
Therefore, in order to ease photonic DIQKD realizations, we aimed at improving DIQKD security proofs.
In ~\cite{Sekatski2021} we propose a new proof which utilizes more information from the available statistics than the sole CHSH score.
This refined analysis allows us to more tightly bound the information an eavesdropper can get access to and, therefore, improve the key rate.
Considering the SPDC setup, our security proof increases the key rate by $37\%$ in the ideal scenario.
However, we did not witness an improvement of the critical efficiency.
We thus tackled the problem of enabling photonic DIQKD realizations from another perspective.
Using reinforcement learning and a custom-made simulation framework, we crafted a method to automate the design of photonic experiments~\cite{Valcarce2022b}.
When applied to DIQKD, our method proposed a new setup yielding both a higher rate and a better robustness to losses compared to the SPDC setup.
Additionally, the flexibility of our approach led us to find a setup based on homodyne measurements, achieving higher CHSH score than the previous best proposal.

The better key rate resulting from our DIQKD protocol lowers requirements on the repetition rate of experiments.
Meanwhile, we show that better robustness to loss can be obtained from better photonic setup designs.
Together, our contributions show that improvements in both DIQKD protocols and experiment designs are necessary for practical DIQKD realizations.


\medbreak

The recent development of DIQKD protocols, are important steps for new proof-of-concept DIQKD experiments.
However, for the low efficiency regime characteristic of photonic setups, further improvements are required to push the key rate by order of magnitude.
One improvement could come from a more general pre-processing of inputs and outcomes, i.e. an extension of noisy pre-processing~\cite{Ho2020}.
Indeed, works in non-locality distillation have shown that pre-processing may amplify the non-local nature of correlations~\cite{Forster2009}.
It would be interesting to find out whether a general pre-processing could enable the distillation of better rates from current DIQKD protocols.

Additionally, in this thesis we focused on asymptotic key rates of DIQKD protocols, but finite-size effects need to be taken into account in order to guarantee that a protocol can actually produce a key~\cite{Tan2021}.
In particular, the entropy accumulation theorem (EAT), the main theoretical tool able to produce finite-size security proofs valid under coherent attacks, is costly -- resulting in lower key rates.
This cost could be mitigated by a modified version of EAT that would yield better bounds, notably on the smooth max entropy of Eve on Bob's outcomes.
Furthermore, for given correlations, bounding the adversary's information in terms of a Bell inequality better suited than CHSH could be used as the min-tradeoff function on which the EAT relies.
Such an inequality can be extracted from the dual formulation of the problem \refeq{Brown}.

\medbreak

For every new security proof and protocol improvement, it is also worth analyzing standard photonic setups, such as the SPDC setup, as well as newly proposed ones.
For example, with the currently best known bound on Eve's uncertainty on the key and the capacity to consider all measurements outcomes in the security proof, positive key rates at practical efficiencies from these setups may already be obtained with the protocol introduced in \cite{Brown2021}.


\medbreak 

Finally, it is necessary to develop new experimental designs for DIQKD implementation.
These new designs should progressively address practical requirements and limitations, e.g. a decent scalability with the distance between parties, the ability to operate at a high rate, or the capacity to transmit photons at telecom wavelength.
Reinforcement learning may help generate new experiments blue prints covering some of these points.
Furthermore, progress in other quantum information processing field, such as quantum computing or quantum simulation, may provide new solutions to these challenges.
For example, as suggested in \cite{Zapatero2023}, arrays of trapped atoms or ions could help parallelize the generation of entanglement, helping heralded entanglement systems to operate at a higher rate.

\paragraph{Towards a Quantum Internet}

While all device-independent protocols possess promising applications, their use in a quantum internet may unlock more powerful and concrete possibilities.
The quantum internet is a hypothetical network of classical and quantum devices, connected by links in which both classical and quantum information transit.
This upgraded version of the current Internet will provide new functionalities with the two most notable ones being communication secured by quantum cryptography and enhance computational power from quantum computers.
If currently many challenges are in the way of a quantum Internet, however, incentives for its realization are flourishing.
Indeed, promises in quantum computing, from fault-tolerant quantum computing heading the roadmap of some companies~\cite{Google2022,Intel2022,IBM2022} to potential ground breaking quantum computation advantages~\cite{Deutsch1992,Shor1994,Grover1996} and applications~\cite{Bauer2020,Paudel2022} are pushing for the accessibility of quantum computers via internet~\cite{Rietsche2022}.
Cloud quantum computing seems therefore to be the first key element for a quantum internet.

\medbreak

The ability to process quantum information in the cloud requires new security guarantees.
With a minimal set of assumptions, self-testing is a privileged candidate to guarantee the proper functioning of elements involved in cloud quantum computing~\cite{Sekatski2018}.
Indeed, self-testing may become the tool of choice for the certification of network links, quantum gates and quantum measurements.
Manufacturers and cloud providers could thus use self-testing to reliably identify faulty elements in their systems.
Future progress in self-testing could lead to even more general protocol where composite systems could be self-tested, scaling the capacity for error detection.

Furthermore, self-testing can be combined with verifiable blind quantum computing~\cite{Fitzsimons2017,Eisert2020} -- a line of research providing security protocols guaranteeing the verifiability and integrity of a computation delegated to a quantum computer -- to provide device-independent certifications of computations~\cite{Reichardt2013,Gheorghiu2015,Hajdusek2015,McKague2016}.

\medbreak

To secure the transit of information, be it classical or quantum, quantum key distribution provides the strongest security guarantee.
Nowadays, QKD is however not privileged by the security agencies of numerous countries, such as France~\cite{ANSSI2020}, the UK~\cite{NCSC2020} and the USA~\cite{NSA2020}.
These agencies unanimously criticize the need for a special infrastructure, the required trust in relay points and the susceptibility to attacks from an eavesdropper.
The former might be covered by infrastructure requirements for quantum computing and encouraged by potential quantum communication applications such as quantum money~\cite{Wiesner1983,Molina2013}.
Furthermore, developing on-chip QKD systems coupled with transmission at telecom wavelength would reduce infrastructure changes to simply adding QKD rack units in data centers. 
Device-independent quantum key distribution protocols address the last two concerns; the device-independent approach removes the need to trust relays and protocols secure against coherent attacks prevent any type of hacking.

\medbreak

In the perspective of a quantum internet, device-independent protocols could bring solutions to many aspects desired by end-users.
Security and privacy, listed as important issues by the Electronic Frontier Foundation~\cite{EFFPrivacy,EFFSecurity}, are among them.
The device-independent framework can guarantee the protection of users' data without having them to trust external actors.
This could allow for truly secure communications and enables the remote processing and long term storage of private data, even by mistrustful third parties.
With guarantees obtainable by end users directly, device-independent protocols may also help build a more decentralize world, as the need for central authorities would become obsolete.
Finally, one should not forget that even if technologies are developed with good intentions, it should ultimately be up to the people through democratic processes to guide their usage.
