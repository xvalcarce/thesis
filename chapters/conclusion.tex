In this thesis we presented our work on device-independent quantum information protocols, improving them with the end goal of easing their experimental implementations, and answering more fundamental questions along the way.
As quantum information applications are expected to have an important impact on current technologies, notably revolutionizing computation and communication tasks, the device-independent framework appears as a necessity.
Indeed, for quantum information protocols to replace their current classical counterparts, stable and robust implementations are as desired as improved performances. 
Moreover, in a global world where communication is key and where manufacturing is scattered across numerous actors, there is the need for cryptographic systems which not only come with the highest security proofs but also with the capability to detect the presence of interferences from the devices they rely on.
Device-independent protocols address these concerns, by allowing certifications of resources and security guarantees made solely from classical outputs of the devices in use, i.e. without relying on assumption on their inner working. 

In the first part of this thesis, we analyzed self-testing, the simplest and most fundamental device-independent protocol, which enables the certification of some quantum resources.
In a second part, we explored device-independent quantum key distribution, a device-independent approach to quantum cryptography, allowing two parties to share a secret symmetric key with a provable security guarantee, based on the fundamental laws of physics. 

In this last part, we briefly recall the results we developed in this thesis before discussing some open questions raised by our contributions as well as by other recent works in the field.
Finally, we put device-independent protocols, and in particular self-testing and DIQKD, into a boarder perspective.
We show these protocols could help build a quantum internet, enhancing the computation and communication capabilities of humanity.

\paragraph{Self-testing} 

Self-testing enables the device-independent certification of certain quantum resources from the presence of specific non-local correlations.
In Chap.~\ref{chap:selftesting} we recalled a method to self-test two-qubit maximally entangled states and maximally incompatible measurements from the maximal violation of the CHSH inequality.
We then explored a more practical scheme, robust self-testing, in Chap.~\ref{chap:robust}, enabling the certification of a singlet-fraction in a noisy and lossy regime, relevant for real world applications.
More specifically, we focus on quantifying the fundamental resources that are required for such robust self-tests.
In Sec~\ref{sec:robust_limits}, we explained how we derived a lower-bound on the CHSH-score below which the robust singlet self-testing fail~\cite{Valcarce2020}.
This lead to some insights on where efforts need to be put to ease the experimental implementation of robust self-testing.
Notably, as this bound is far from the local CHSH bound, and out of reach for fully-photonic experiments, we assessed the need for robust self-testing protocols beyond the CHSH score.
Addressing this need, we formulated an original protocol, that we briefly reviewed in Sec.\ref{sec:robust_XY}.
Based on a more refined analysis of the correlations, this protocol provides better robustness bounds, and, in the case of asymmetric noises, enables robust self-testing even below the CHSH lower-bound we derived~\cite{Valcarce2022}.

\medbreak

The works presented in the first part of this thesis show the need for more robust self-testing protocols and point at some directions where improvements can be obtained, but also raise some more fundamental questions.
First, the CHSH-score threshold we derived is still far from the bound given by the best CHSH-based self-testing protocol~\cite{Kaniewski2016}.
Therefore an improvement is to be expected on the threshold or on the local isometries proposed in \cite{Kaniewski2016} or both.
Then, analogously to what has been done for DIQKD~\cite{Brown2021}, one can hope for a robust self-testing protocol harnessing all of the available statistics.
Insights obtained from our generalized-CHSH based self-test show that such a protocol should help providing self-tests that are robust to any type of noises.
This appears as a crucial step not only to ease the implementation of self-testing, but also to make self-testing a handy and flexible certification tool, that could be used as a complementary tool with tomography.
Finally, better robustness bound could arise when considering a scenario with more than 2 inputs and outputs.
However, this would require a new protocol derivation that does not rely on Jordan's lemma.
Again, such a proof could come as an inspiration of the approach taken in \cite{Brown2021}.

\medbreak

More broadly, robust self-testing methods should be extended to enable the certification of not just states, but entire quantum systems.
First, the robust self-testing of quantum channels, introduced in \cite{Sekatski2018}, could be extended to certify quantum measurements.
A framework for the robust self-testing of joint quantum measurements could then be developed.
Finally, this may lead to \textit{complete self-tests}, certifying at once both states and measurements.
For each of these method, it is desired to have proofs valid in non-IID scenarios to enable practical applications.
At first glance, the approach based on estimators on the statistics demonstrated in \cite{Bancal2021} could be extended to these more complete self-tests. 


%Similarly to what is done with the self-test of quantum state, propose a way to robust self-test measurement.
%This could lead to the robust self-test of entire quantum channel or even of quantum circuits.
%This method could be use as a complementary approach to quantum tomography, allowing to debug system.

\paragraph{DIQKD}

\acrfull{DIQKD} allow two parties to share a secret and identical cryptographic key in a provable way.
In Chap.~\ref{chap:diqkd}, we discussed the motivations for DIQKD and the steps involved in a typical DIQKD protocol.
Security proofs, in the form of key rates, are then reviewed in Chap.~\ref{chap:entropybound}. 
This includes the fundamental key rate expression~\cite{Devetak2005}, and a practical key rate expression that has been derived from the CHSH score~\cite{Pironio2009}. 
We then showed some improvements that have been build on top of this key rate, notably fine-grained error-correction~\cite{Ma2012} and noisy pre-processing~\cite{Ho2020,Woodhead2021}. 
In order to ease concrete experimental realizations of DIQKD, we proposed a new security proof based on generalized-CHSH inequalities~\cite{Sekatski2021}, that we briefly reviewed in Sec.~\ref{sec:Pavel}.
This proof enhances key rates in most cases, as well as the robustness to losses when considering certain classes of state.
Finally, the recent work \cite{Brown2021} that has introduced key rate based on the full statistics, yielding the best rate and robustness, is discussed in Sec~\ref{sec:Brown}.
After reviewing the different experimental platforms that can be used to implement DIQKD, in Chap.~\ref{chap:implementing_diqkd} we presented how we combined reinforcement learning and a custom-made simulation framework to automate the design of photonic experiments~\cite{Valcarce2022b}.
Notably, when applied to DIQKD, our method proposed a setup yielding a higher rate and robustness to losses when compared to the SPDC setup, the standard photonic setup for Bell non-locality.
Additionally, the flexibility of this approach led us to find a setup based on homodyne measurements, achieving higher CHSH score than the previous best proposal.


\medbreak

The recent development of DIQKD protocols, are important steps for new proof-of-concept DIQKD experiments.
However, considering the photonic platform as the most promising one for long-term DIQKD applications, more efforts need to be put to improve key rates for the low efficiency regime which is characteristic of these setups.
One improvement could come from a more general pre-processing of inputs and outcomes, i.e. an extension of noisy pre-processing~\cite{Ho2020}.
Indeed, works in non-locality distillation have shown that pre-processing may amplify the non-local nature of correlations~\cite{Forster2009}.
Therefore, a general pre-processing may enable the distillation of better rates from current DIQKD protocols.

Additionally, if in this thesis we focus on asymptotic key rates of DIQKD protocols, in practice, however, finite-size effects need to be taken into account~\cite{Tan2021}.
In particular, the entropy accumulation theorem (EAT) used to derive security proofs valid under coherent attacks becomes costly -- resulting in lower key rates.
However, this cost could be mitigated by a modified version of EAT that would yield better bounds, notably on the smooth max entropy of Eve on Bob's outcomes.
Furthermore, for given correlations, a better suited Bell inequality than CHSH could be used as the min-tradeoff function on which the EAT relies.
Such an inequality can be extracted from the dual formulation of the problem \refeq{Brown}.

\medbreak

In parallel to protocols improvements, it is worth analyzing standard photonic setups, such as the SPDC setup, as well as newly proposed one, whenever a better security proof becomes available.
With the currently best bound on Eve's uncertainty on the key and the capacity to consider all measurements outcomes in the security proof, positive key rates at practical efficiencies from these setups may be obtained with the protocol introduced in \cite{Brown2021}.

\medbreak 

Finally, it is necessary to develop new experimental designs for DIQKD experiments.
These new designs should progressively address practical requirements and limitations, e.g. a decent scalability with the distance between parties, the ability to operate at a high rate, or the capacity to transmit photons at telecom wavelength.
Reinforcement learning may help generate new experiments blue prints covering some of these points.
Furthermore, progress in other quantum information processing field, notably quantum computing, may provide new solutions to these challenges.
For example, as suggested in \cite{Zapatero2023}, arrays of atoms or ions trapped could help parallelize the generation of entanglement, helping heralded entanglement systems to operate at a higher rate.

\paragraph{Towards a Quantum Internet}

The quantum internet is an hypothetical network of classical and quantum devices, connected by links in which transit both classical and quantum information.
This upgraded version of the current Internet will provide new functionalities with the two most notable ones being communications secured by quantum cryptography and enhance computational power thanks to quantum computers.
If currently many challenges are in the way of a quantum Internet, however, incentives for its realization are flourishing.
Indeed, promises in quantum computing, from fault-tolerant quantum computing heading the roadmap of some companies~\cite{Google2022,Intel2022,IBM2022} to potential ground breaking quantum computation advantages~\cite{Deutsch1992,Shor1994,Grover1996} and applications~\cite{Bauer2020,Paudel2022} are pushing for the accessibility of quantum computers via internet~\cite{Rietsche2022}.
Cloud quantum computing seems therefore to be the first key element for a quantum internet.

\medbreak

The ability to process quantum information in the cloud requires new security guarantees.
Thanks to a minimal set of assumptions, self-testing is a privileged candidate to guarantee the proper functioning of elements involved in cloud quantum computing~\cite{Sekatski2018}.
Indeed, self-testing may become the tool of choice for the certification of network links, quantum gates and quantum measurements.
Manufacturers and cloud providers could thus use self-testing to reliably identify faulty elements in their systems.
Future progress in self-testing could lead to even more general protocol where composite systems could be self-tested, scaling the capacity for error detection.

Furthermore, self-testing can be combined with verifiable blind quantum computing~\cite{Fitzsimons2017,Eisert2020} -- a line of research providing security protocols guaranteeing the verifiability and integrity of a computation delegated to a quantum computer -- to provide device-independent certifications of computations~\cite{Gheorghiu2015,Hajdusek2015}.

\medbreak

To secure the transit of information, be it classical or quantum, quantum key distribution provides the strongest security guarantee.
Nowadays, QKD is however not privileged by the security agencies of numerous countries, such as France~\cite{ANSSI2020}, the UK~\cite{NCSC2020} and the USA~\cite{NSA2020}.
These agencies unanimously criticize the need for a special infrastructure, the required trust in relay points and the susceptibility to attacks from an eavesdropper.
The former might be cover by infrastructure requirements for quantum computing and encouraged by potential quantum communication applications such as quantum money~\cite{Wiesner1983,Molina2013}.
Furthermore, developing on-chip QKD systems coupled with transmission at telecom wavelength would reduce infrastructure changes to simply adding QKD rack units in data centers. 
Device-independent quantum key distribution protocols address the last two concerns; the DI approach remove the trust needed in relays and protocols secure against coherent attacks prevent any type of hacking.


%Device-independent protocols a
%quantum internet: quantum computing will be in the cloud. 
%slef-testing help certify network link so ++ security for sensible applications.
%QKD is not privileged by countries UK, France, US, however the DI approach + the need for secure quantum link for quantum computing will help developped the infrastructure.
%Boom Quantum Internet.
